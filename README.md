# Cognivern: Agent Reliability + Proof Layer

Cognivern is a **Run Ledger + Ingestion API** for teams building in the agentic era.

It gives you a durable, queryable record of what agents did (steps + artifacts), with optional **verifiability** via Chainlink primitives (price feeds today; CRE-style workflows as the execution target).

**Wedge:** donâ€™t replace your agent runtime â€” just *send runs* to Cognivern.

## What it does (today)

- **Run Ledger UI**: browse runs, drill into steps and artifacts, copy run links/JSON.
- **Data-plane ingestion**: `POST /ingest/runs` (project-scoped ingest keys).
- **Multi-project support**: `projectId` scoping across runs.
- **Persistence**: run history and usage survive restarts (local-first JSONL/JSON).
- **Commercial primitives**: per-project quotas, usage headers, token-level telemetry.
- **Chainlink integration (differentiator)**: forecasting workflow reads Arbitrum Chainlink price feeds and can optionally attest forecasts.

## Who itâ€™s for

- Teams running agents in production who need **debugging, governance, and accountability**.
- Builders shipping on-chain automation who need **proof** for high-stakes actions.

## Key idea

Agents are cheap. **Trust and reliability are expensive.**

Cognivern is the layer that turns â€œagent runsâ€ into something you can operate, audit, and bill.

## ğŸ¯ Chainlink Convergence Hackathon

### Target Tracks
- ğŸ¤– **AI Agents: DeFi & Web3** â€” AI-powered prediction market agent consuming CRE workflows
- ğŸ”— **AI Agents: Multi-agent & orchestration** â€” Multi-LLM orchestrated forecasting with decentralized consensus
- ğŸ† **Grand Prize** â€” Best overall project showcasing Chainlink technologies

### CRE Integration
- âœ… **Cron-Triggered Workflows** â€” Scheduled forecasting pipeline running on Chainlink DON
- âœ… **HTTP Capability** â€” Sapience market data fetched with multi-node consensus
- âœ… **Confidential HTTP** â€” Private LLM API calls with enclave execution
- âœ… **EVM Read** â€” Chainlink Data Feeds for real-time price inputs
- âœ… **EVM Write** â€” Consensus-verified EAS attestation submission on Arbitrum

### Key Features
- **ğŸ“Š Live "Thoughts" Dashboard** â€” Real-time display of agent reasoning and decision-making process
- **ğŸ† Horizon-Weighted Strategy** â€” Mathematically optimized market selection for maximum accuracy scoring
- **ğŸ” Confidential AI** â€” LLM reasoning stays private via CRE enclaves, preventing front-running
- **ğŸ›¡ï¸ Governance Native** â€” Policy enforcement layer with on-chain risk guardrails

## Quick Start

### Prerequisites
- Node.js v20.14+
- pnpm
- Arbitrum ETH for gas fees (Address: `0xc8F0D4FF31166Daf37804C20eeFd059e041E64dC`)

### Installation

```bash
git clone https://github.com/thisyearnofear/cognivern.git
cd cognivern
pnpm install
```

### Configuration

Cognivern enforces a strict **"No Mocks"** policy. Features only activate when valid production keys are present.

Create `.env` file:

```env
# Sapience / Arbitrum (REQUIRED)
ARBITRUM_RPC_URL=https://arb1.arbitrum.io/rpc
SAPIENCE_PRIVATE_KEY=your_private_key_here

# Resilient LLM Layer (REQUIRED)
ROUTEWAY_API_KEY=your_routeway_key
GROQ_API_KEY=your_groq_key

# Recall Network (REQUIRED for Memory)
RECALL_API_KEY=your_recall_key
RECALL_BUCKET=agent-memory

# Filecoin FVM (REQUIRED for Governance)
FILECOIN_RPC_URL=https://api.calibration.node.glif.io/rpc/v1
FILECOIN_PRIVATE_KEY=your_private_key_here
GOVERNANCE_CONTRACT_ADDRESS=0x...
```

### Run the backend

```bash
pnpm install
pnpm build
pnpm start
```

### Ingest a run from any agent

```bash
# Configure projects/keys
export COGNIVERN_PROJECTS="default:Default Project"
export COGNIVERN_INGEST_KEYS="default=dev-ingest-key"

# Send a run
curl -X POST http://localhost:3000/ingest/runs \
  -H 'Authorization: Bearer dev-ingest-key' \
  -H 'X-PROJECT-ID: default' \
  -H 'Content-Type: application/json' \
  -d '{"runId":"123","projectId":"default","workflow":"forecasting","mode":"local","startedAt":"2026-01-01T00:00:00.000Z","finishedAt":"2026-01-01T00:00:01.000Z","ok":true,"steps":[],"artifacts":[]}'
```

Or use the included example:
```bash
pnpm ingest-example
```

## Deployment

See [docs/DEPLOYMENT.md](./docs/DEPLOYMENT.md) for the standard artifact-based release process (build locally, deploy to Hetzner, rollback via symlink).

## ğŸ—ï¸ Architecture: CRE-Powered Prediction Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CRE Workflow DON                              â”‚
â”‚                                                                 â”‚
â”‚  [Cron Trigger]  â”€â”€â†’  [HTTP Fetch]  â”€â”€â†’  [Confidential HTTP]   â”‚
â”‚   Every 10 min        Market Data         LLM Reasoning         â”‚
â”‚                       (consensus)         (private enclave)     â”‚
â”‚                            â”‚                    â”‚               â”‚
â”‚                            â–¼                    â–¼               â”‚
â”‚                     [EVM Read]           [EVM Write]            â”‚
â”‚                     Price Feeds          EAS Attestation        â”‚
â”‚                     (consensus)          (consensus)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Arbitrum One   â”‚
                    â”‚  EAS Attestation â”‚
                    â”‚  + Data Feeds    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Multi-LLM Resilience Layer
1. **Tier 1 (Routeway.ai):** High-context reasoning using Moonshot Kimi K2 via Confidential HTTP.
2. **Tier 2 (Groq):** Ultra-fast failover using Llama 3.3 (70B) if Tier 1 is throttled or offline.

Both LLM calls execute within CRE's Confidential HTTP capability â€” API keys and reasoning remain private within enclave execution.

## ğŸ† Evidence of Prior Work

Cognivern has a proven track record from the Sapience Hackathon:
- **Arbiscan (EAS):** [View Agent Wallet & Attestations](https://arbiscan.io/address/0xc8F0D4FF31166Daf37804C20eeFd059e041E64dC)
- **Real-Time Reasoning:** Live "Thoughts" feed generated by the Multi-LLM layer
- **On-Chain History:** Existing EAS attestations demonstrate production-ready forecasting

## ğŸ“š Documentation

| Doc | Description |
| :--- | :--- |
| **[Architecture](./docs/ARCHITECTURE.md)** | System overview, components, and design |
| **[Developer Guide](./docs/DEVELOPER.md)** | API reference, testing, and contributing |
| **[CRE Integration](./docs/CRE.md)** | Chainlink workflow implementation |
| **[Deployment](./docs/DEPLOYMENT.md)** | Release process, rollback, and operations |

## ğŸ“œ License

MIT
